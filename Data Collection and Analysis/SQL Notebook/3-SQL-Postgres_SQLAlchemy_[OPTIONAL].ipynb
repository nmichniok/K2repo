{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Postgres and SQLAlchemy\n",
    "In this exercise we'll install and begin using a new SQL database system called Postgres, and then connect to it and work a bit with SQLAlchemy.\n",
    "\n",
    "## Postgres\n",
    "There are a pelethora of available relational database management systems.  Some are free and open source while others come with a very hefty price.  Several of the more popular systems are Oracle, MySQL, Microsoft SQL Server, SQLite, and what we will be using for this tutorial, PostgreSQL.  Choosing the right database system for your particular use is a very complex problem, but very often one will take into account cost, scalability, and available packages.  PostgreSQL has the advantage of being free and, since it's been around for a long time, having a large selection of tools for many different tasks (PostGIS is a very good GIS database system for example).  For an extensive list of many different database systems and how they compare, take a look at the [wiki](https://en.wikipedia.org/wiki/Comparison_of_relational_database_management_systems).\n",
    "\n",
    "### Installation\n",
    "To start off, you'll need to download [PostgreSQL](https://www.postgresql.org/download/) for your operating system.  This tutorial was written for Windows.  If you are using Linux, you will likely have a few other steps during the install with properly setting up users and permissions.  [Arch Linux](https://wiki.archlinux.org/index.php/PostgreSQL) for example, requires a few extra steps, so consult your OS documentation for additional info.\n",
    "\n",
    "The download link for Windows and Mac, includes the Postgres server and the graphic administrator tool pgAdmin.  Again, if you are on Linux, you may have to download and install this tool seperately.\n",
    "\n",
    "During the Windows install, you'll be promted for a database admin password, a port, and locale.  Set the password to something you'll remember, use the default port `5432`, and just use the default system locale.\n",
    "\n",
    "After the install, you'll be promted to load `Stack Builder`, an interface to install additional tools for Postgres.  We won't be installing any, but feel free to take a look to see what is available.  Of note may be some of the previous version servers which you may find yourself needing, and PostGIS, their geospatial database system.\n",
    "\n",
    "### Creating a table\n",
    "Before diving into creating a table in your newly installed Postgres database, we'll first need some datasets.  Head over to the [R datasets repository](https://vincentarelbundock.github.io/Rdatasets/datasets.html) and download the mtcars and Titanic datasets.\n",
    "\n",
    "Now with the data, we can make a table.  Load pgAdmin and navigate to `File -> Preferences -> Paths -> Binary paths` and set the `PostgreSQL Binary Path` to the `/bin` folder in your Postgres install directory.  On Windows, it should be something like `C:\\Program Files\\PostgreSQL\\9.6\\bin`.  Setting this path, tells pgAdmin where to find the various tools (default and otherwise) that have installed.\n",
    "\n",
    "After setting the path, we need to create a Schema.  A Schema can be thought of as a collection of loosely related tables.  For example, if your company wanted to keep financial records and, say, for an airline, flight data on the same database, they will likely end up in different schemas.  A full discussion of schemas is beyond the scope of this tutorial, but know that when writing complex queries, you will run into problems when trying to retrieve data if your tables are in different schemas.  For a more complete discription, check out the [wiki](https://en.wikipedia.org/wiki/Database_schema).\n",
    "\n",
    "To create a schema, in the `Browser` pane on the left side of pgAdmin, click `Servers -> PostgreSQL x.x -> Database -> postgres` and then right click on `Schema` and then `Create -> Schema...` and set the name as `tutorial`, keeping all other fields to their defaults.  Click `Save` and verify that the new schema was created.\n",
    "\n",
    "Expand the `tutorial` schema and right click on `Tables -> Create`.  Set the name as `mtcars` and click on the `columns` tab.  Now some data import tools will automatically detect column data types, but for this exercise, we're going to enter them manually.  Also, it is very important to take care when choosing the data type.  In our case, we are only bringing in a few rows so disk space isn't an issue, but for very large databases you will often find yourself in a situation where choosing the proper datatype will have a significant impact.\n",
    "\n",
    "Add a column by clicking the `+` icon on the top right of the window and add the following columns with data types.\n",
    "\n",
    "`\n",
    "name character varying\n",
    "mpg numeric\n",
    "cyl integer\n",
    "disp numeric\n",
    "hp numeric\n",
    "drat numeric\n",
    "wt numeric \n",
    "qsec numeric\n",
    "vs integer\n",
    "am integer\n",
    "gear integer\n",
    "carb integer\n",
    "`\n",
    "\n",
    "Click save and verify that you can expand the `columns` icon below your table and that it contains all the columns you added.\n",
    "\n",
    "We are now ready to import the data.  Right click on `mtcars -> Import/Export` and in the new window, change to `Import` by clicking `Export`, set `Format = csv`, `Header = yes`, `Delimiter = '`, and click the `...` and navigate to `mtcars.csv`.  When done, hit okay and wait a few seconds.  If all worked properly, you should get a small dialog in the bottom right corner saying that the import was sucessful.\n",
    "\n",
    "Now let's check to see if the data was imported correctly.  Right click on the table `-> View Data -> View All Rows`.  A new window should pop up on the right, displaying the `mtcars` data set.  Notice above this window is some SQL, reading\n",
    "\n",
    "`SELECT * FROM tutorial.mtcars`\n",
    "\n",
    "indicating the code which was run to return the results.\n",
    "\n",
    "With our data in the table, let's run a simple query.  Right click on the table `-> Query Tool`.  A new window will pop up on the right and enter at the top\n",
    "\n",
    "`SELECT name, mpg, cyl, hp FROM tutorial.mtcars WHERE cyl = 6`\n",
    "\n",
    "The results of the query will be displayed below.  Now let's say that you want to export your query results.  To do so, click the last icon on the right labeled `Download as csv` to save it to disk.\n",
    "\n",
    "**Exercise:** Now that the mtcars data is in our Postgres Database, all we need is the Titanic data.  Do the same as above, bringing in the Titanic.csv we downloaded earlier. *Hint:* The data contains some `NA` values.  You could just import the column as a `character`, but there is a proper way to do this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SQLAlchemy\n",
    "SQLAlchemy is a SQL toolkit and object-relational-mapper (ORM) for Python.  The basic idea is that as databases get larger and larger, and as they begin to be incorporated into a workflow, it becomes advantageos to begin to think of them as objects (in the OOP sense).  Or stated more precicely from the [wiki](https://en.wikipedia.org/wiki/SQLAlchemy).\n",
    "\n",
    ">SQLAlchemy provides \"a full suite of well known enterprise-level persistence patterns, designed for efficient and high-performing database access, adapted into a simple and Pythonic domain language\". SQLAlchemy's philosophy is that SQL databases behave less and less like object collections the more size and performance start to matter, while object collections behave less and less like tables and rows the more abstraction starts to matter. For this reason it has adopted the data mapper pattern (like Hibernate for Java) rather than the active record pattern used by a number of other object-relational mappers.[4] However, optional plugins allow users to develop using declarative syntax.\n",
    "\n",
    "In this exercise, we'll go over the basics of getting started with SQLAlchemy.  Before proceding, ensure that you have both the `sqlalchemy` and `psycopg2` modules installed.\n",
    "\n",
    "### Connecting to our Postgres Database\n",
    "The first order of business is to load up SQLAlchemy and get it conneted to the database we made in the previous section.  Let's start off by writing a function to connect to our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "def connect(user, password, db, schema, host='localhost', port = 5432):\n",
    "    \"\"\"Connects SQLAlchemy to a Postgres database\n",
    "        \n",
    "    Args:\n",
    "        user: Postgres user\n",
    "        password: User password\n",
    "        db: Database name\n",
    "        schema: Schema name\n",
    "        host: Host default as localhost\n",
    "        port: Postgres port, default 5432\n",
    "            \n",
    "    Returns:\n",
    "        A connection and metadata object\n",
    "    \"\"\"\n",
    "    # Generate the URL for our database\n",
    "    url = 'postgresql://{}:{}@{}:{}/{}'\n",
    "    url = url.format(user, password, host, port, db)\n",
    "\n",
    "    # Get the connection object\n",
    "    con = sqlalchemy.create_engine(url, client_encoding = 'utf8')\n",
    "\n",
    "    # Get the metadata object\n",
    "    meta = sqlalchemy.MetaData(bind = con)\n",
    "    meta.reflect(bind = con, schema = schema)\n",
    "\n",
    "    return con, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con, meta = connect(user = 'postgres', password = 'password', schema = 'tutorial', db = 'postgres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, replacing `user` and `password` with your own values if you used otherwise.  Let's take a look at some of the metadata SQLAlchemy generated for us.  The following will show us all the tables in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tutorial.titanic\n",
      "tutorial.mtcars\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import Table, Column, Integer, String, ForeignKey\n",
    "\n",
    "for table in meta.tables:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which says that our database schema `tutorial` contains two tables named `Titanic` and `mtcars`, just like expected.  We can also look at the columns using the `c` attribute of the MetaData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic.idx\n",
      "titanic.Name\n",
      "titanic.PClass\n",
      "titanic.Age\n",
      "titanic.Sex\n",
      "titanic.Survived\n",
      "titanic.SexCode\n"
     ]
    }
   ],
   "source": [
    "for col in meta.tables['tutorial.titanic'].c:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives us the names of the columns in `titanic`.\n",
    "\n",
    "**Exercise:** Print out the metadata for the columns of the `mtcars` table, including the data types for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries\n",
    "We can also use SQLAlchemy to query our database.  For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Allen, Miss Elisabeth Walton', '1st', Decimal('29'), 'female', 1, 1)\n",
      "(2, 'Allison, Miss Helen Loraine', '1st', Decimal('2'), 'female', 0, 1)\n",
      "(3, 'Allison, Mr Hudson Joshua Creighton', '1st', Decimal('30'), 'male', 0, 0)\n",
      "(4, 'Allison, Mrs Hudson JC (Bessie Waldo Daniels)', '1st', Decimal('25'), 'female', 0, 1)\n",
      "(5, 'Allison, Master Hudson Trevor', '1st', Decimal('0.92'), 'male', 1, 0)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.sql import select\n",
    "t = meta.tables['tutorial.titanic'] # table object to use\n",
    "s = select([t])\n",
    "\n",
    "results = con.execute(s.limit(5))\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will select all columns from our table.  Notice that we tacked on the `limit()` function at the end just as you would with a normal SQL statement.  If we wanted to select only a subset of the columns, we would put them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Allen, Miss Elisabeth Walton', '1st', Decimal('29'), 1)\n",
      "('Allison, Miss Helen Loraine', '1st', Decimal('2'), 0)\n",
      "('Allison, Mr Hudson Joshua Creighton', '1st', Decimal('30'), 0)\n",
      "('Allison, Mrs Hudson JC (Bessie Waldo Daniels)', '1st', Decimal('25'), 0)\n",
      "('Allison, Master Hudson Trevor', '1st', Decimal('0.92'), 1)\n"
     ]
    }
   ],
   "source": [
    "t = meta.tables['tutorial.titanic'] # table object to use\n",
    "s = select([t.c.Name, t.c.PClass, t.c.Age, t.c.Survived])\n",
    "\n",
    "results = con.execute(s.limit(5))\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, we can also add a where clause to the query as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Abbott, Mrs Stanton (Rosa)', '3rd', Decimal('35'), 'female', 1)\n",
      "('Abelseth, Miss Anna Karen', '3rd', Decimal('16'), 'female', 1)\n",
      "('Abraham, Mrs Joseph (Sophie Easu)', '3rd', Decimal('18'), 'female', 1)\n",
      "('Ahlin, Mrs Johanna Persdotter', '3rd', Decimal('40'), 'female', 0)\n",
      "('Aks, Mrs Sam (Leah Rosen)', '3rd', Decimal('18'), 'female', 1)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.sql import and_\n",
    "\n",
    "t = meta.tables['tutorial.titanic'] # table object to use\n",
    "s = select([t.c.Name, t.c.PClass, t.c.Age, t.c.Sex, t.c.Survived])\n",
    "\n",
    "results = con.execute(s.where(and_(t.c.PClass == '3rd', t.c.Sex == 'female')).limit(5))\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in order to use logical operators (also called conjunctions), we had to import them and use them in the where clause.  In addition to `and_()` there are several others such as `or_()`, and `not_()`.  Consult the SQLAlchemy [documentation](http://docs.sqlalchemy.org/en/latest/) for more information.\n",
    "\n",
    "Sometimes in practice, you may already have the logic of a query worked out and written down as a SQL statement, and as you can see, the logical operators will get messy very qickly. Luckily, SQLAlchemy includes a very handy function called `text()` which allows you to enter the SQL directly into your Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mazda RX4', 6, Decimal('110'), Decimal('21'))\n",
      "('Mazda RX4 Wag', 6, Decimal('110'), Decimal('21'))\n",
      "('Hornet 4 Drive', 6, Decimal('110'), Decimal('21.4'))\n",
      "('Valiant', 6, Decimal('105'), Decimal('18.1'))\n",
      "('Merc 280', 6, Decimal('123'), Decimal('19.2'))\n",
      "('Ferrari Dino', 6, Decimal('175'), Decimal('19.7'))\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy.sql import text\n",
    "\n",
    "s = text(\"SELECT name, cyl, hp, mpg FROM tutorial.mtcars WHERE cyl = :c AND mpg > :m\")\n",
    "\n",
    "results = con.execute(s, c = 6, m = 18)\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the query, we `:c` and `:m` were left as place holders for values which were then fed as additional arguments to the `execute()` function.  This is very useful, especially if you want to generate many different tables with different parameter settings.  We can also use aggregate functions and group by clauses.  For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 14)\n",
      "(4, 11)\n",
      "(6, 7)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func\n",
    "\n",
    "t = meta.tables['tutorial.mtcars']\n",
    "stmt = select([t.c.cyl, func.count(t.c.name).label('Count')]).group_by(t.c.cyl)\n",
    "\n",
    "results = con.execute(stmt)\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "returns the counts grouped by `cyl`.  Note the use of the `label()` function which serves to add an alias to the column like the `AS` keyword in SQL.\n",
    "\n",
    "**Exercise:** Write a query to return the average `mpg` for all rows with a `hp` greater than or equal to 115, grouped by `cyl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables and Inserts\n",
    "Let's add a couple of tables to our database.  To start off, we'll have to provide SQLAlchemy with some metadata for what sort of data our table will contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Table, Column, Integer, Numeric, String, ForeignKey\n",
    "\n",
    "grades = Table('grades', meta,\n",
    "               Column('name', String, primary_key = True),\n",
    "               Column('grade', Integer),\n",
    "               Column('gpa', Numeric)\n",
    ")\n",
    "\n",
    "dem = Table('dem', meta,\n",
    "            Column('name', String, ForeignKey('grades.name')),\n",
    "            Column('age', Integer),\n",
    "            Column('sex', String)\n",
    ")\n",
    "\n",
    "meta.create_all(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open up pgAdmin and you should see the two tables under the `public` schema.  Now let's add a few records to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x27eeb28c3c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grades = [\n",
    "    {'name': 'Arnold', 'grade': 3, 'gpa': 2.7},\n",
    "    {'name': 'Gerald', 'grade': 2, 'gpa': 2.1},\n",
    "    {'name': 'Helga', 'grade': 4, 'gpa': 3.3},\n",
    "    {'name': 'Phoebe ', 'grade': 3, 'gpa': 3.8}\n",
    "]\n",
    "\n",
    "data_dem = [\n",
    "    {'name': 'Arnold', 'age': 14, 'sex': 'male'},\n",
    "    {'name': 'Gerald', 'age': 15, 'sex': 'male'},\n",
    "    {'name': 'Helga', 'age': 12, 'sex': 'female'}\n",
    "]\n",
    "\n",
    "con.execute(meta.tables['grades'].insert(), data_grades)\n",
    "con.execute(meta.tables['dem'].insert(), data_dem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to verify that it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arnold', 3, Decimal('2.7'))\n",
      "('Gerald', 2, Decimal('2.1'))\n",
      "('Helga', 4, Decimal('3.3'))\n",
      "('Phoebe ', 3, Decimal('3.8'))\n"
     ]
    }
   ],
   "source": [
    "t = meta.tables['grades']\n",
    "results = con.execute(t.select())\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arnold', 14, 'male')\n",
      "('Gerald', 15, 'male')\n",
      "('Helga', 12, 'female')\n"
     ]
    }
   ],
   "source": [
    "t = meta.tables['dem']\n",
    "results = con.execute(t.select())\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins\n",
    "The final topic to cover here are joins.  Since now we have two new tables with a common element, we can demonstrate how to do this in SQLAlchemy.  Let's take a look at the output of the following code segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grades JOIN dem ON grades.name = dem.name\n"
     ]
    }
   ],
   "source": [
    "print(meta.tables['grades'].join(meta.tables['dem']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because we defined the foreign key relationship above when we created the tables, SQLAlchemy already knows what columns to join the tables on.  Also, you can now see that under the hood, SQLAlchemy is just building SQL queries to pass to Postgres for you.  Now let's actually join the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arnold', 14, 'male', 3, Decimal('2.7'))\n",
      "('Gerald', 15, 'male', 2, Decimal('2.1'))\n",
      "('Helga', 12, 'female', 4, Decimal('3.3'))\n"
     ]
    }
   ],
   "source": [
    "g = meta.tables['grades']\n",
    "d = meta.tables['dem']\n",
    "t = g.join(d)\n",
    "\n",
    "s = select([g.c.name, d.c.age, d.c.sex, g.c.grade, g.c.gpa]).select_from(t)\n",
    "\n",
    "results = con.execute(s)\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the above we made use of `select_from()` function.  Let's take a look at some of the objects going into the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table('grades', MetaData(bind=Engine(postgresql://postgres:***@localhost:5432/postgres)), Column('name', String(), table=<grades>, primary_key=True, nullable=False), Column('grade', Integer(), table=<grades>), Column('gpa', Numeric(), table=<grades>), schema=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, `g` is a `Table` object.  But what actually happens when we call the `select()` function of a `Table` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT grades.name, grades.grade, grades.gpa \n",
      "FROM grades\n"
     ]
    }
   ],
   "source": [
    "print(g.select())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like SQLAlchemy is actually building SQL queries for us while making use of OOP in Python.  Now let's see what the object `t` looks like which was the result of the join above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.sql.selectable.Join at 0x27eeb214710; Join object on grades(2744134338936) and dem(2744134337424)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it's a `join` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grades JOIN dem ON grades.name = dem.name\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like the `FROM` clause in a SQL statement with a join.  This means that the `select_from()` function actually replaces the `FROM` clause from a normal `select()` function all, placing the proper clause for a `JOIN`.  This, in short, is the real advantage for building a Pythonic system using an ORM when working with a database.  When working with pure SQL scripts in a workflow, you'll often find yourself copying and pasting much of the same queries over and over again.  SQLAlchemy instead provides a wide array of functions which can be used to build these queries on the fly, saving you much time and headaches.\n",
    "\n",
    "We can also perform outer joins with SQLAlchemy.  This is pretty straightforward and can be done by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arnold', 14, 'male', 3, Decimal('2.7'))\n",
      "('Gerald', 15, 'male', 2, Decimal('2.1'))\n",
      "('Helga', 12, 'female', 4, Decimal('3.3'))\n",
      "('Phoebe ', None, None, 3, Decimal('3.8'))\n"
     ]
    }
   ],
   "source": [
    "g = meta.tables['grades']\n",
    "d = meta.tables['dem']\n",
    "t = g.outerjoin(d)\n",
    "\n",
    "s = select([g.c.name, d.c.age, d.c.sex, g.c.grade, g.c.gpa]).select_from(t)\n",
    "\n",
    "results = con.execute(s)\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the missing values for Phoebe were replaced with `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**\n",
    "1. Go to the [R Dataset Repository](https://vincentarelbundock.github.io/Rdatasets/datasets.html) and download the [Iraq Vote](https://vincentarelbundock.github.io/Rdatasets/csv/pscl/iraqVote.csv) and [SAT](https://vincentarelbundock.github.io/Rdatasets/csv/mosaicData/SAT.csv) datasets.  After you have them, connect to your database using SQLAlchemy, insert the data, and verify that it worked correctly using SQLAlchemy.\n",
    "1. Using SQLAlchemy, select all states which had a salary greater than `30.000` and a math score greater than `500`.\n",
    "1. Using SQLAlchemy, count the votes for the war, versus votes against the war for Republican senators, versus for the war not Republican senators.\n",
    "1. Using SQLAlchemy, calculate the average SAT score for states that voted for the Iraq war, those that voted against, and those with split votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
